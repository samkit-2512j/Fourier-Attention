# FART-INLP  
Repository for maintaining all code, experiments, and documentation related to the INLP Project.

---

## Branch Details

The repository contains **7 active branches**:

1. **`main`**  
   Hosts all essential documentation, reports, and submission-related materials.

2. **`FNET-pretrained-SWAG`**  
   Contains code and results comparing baseline BERT with its Fourier-enhanced counterpart (FNet), evaluated on the SWAG dataset.

3. **`BART-SST`**  
   Includes scripts for fine-tuning both base BART and Fourier-enhanced BART models on the SST dataset.

4. **`fftNET`**  
   A modified fork of [jacobfa/fft](https://github.com/jacobfa/fft), adapted for benchmarking on the CIFAR-10 dataset using Transformer, FFT, and FFTNet models.

5. **`FourierTransform`**  
   An unofficial fork of [lumia-group/fouriertransformer](https://github.com/lumia-group/fouriertransformer).  
   _Note: Minimal activity on this branch due to computational issues of experimenting this._

6. **`jedi-base`**  
   An improved version of the [JEDI](https://github.com/Willy-Chan/JEDI) repository, with added metrics and support for fine-tuning BART-based models.

7. **`phase-incorp`**
    We investigated the significance of the complex component of the Fourier Transform on multimodal datasets , specifically, images (CIFAR-10) and audio (Speech Commands).

---

## Contributors : 

- **Samkit Jain** – <samkit.jain@students.iiit.ac.in> ([Profile](https://github.com/samkit-2512j))
- **Aryan Garg** – <aryan.garg@stuudents.iiit.ac.in> ([Profile](https://github.com/AryanGarg13))

